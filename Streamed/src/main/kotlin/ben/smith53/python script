#!/usr/bin/env python3
import urllib.request
import urllib.error
import urllib.parse
import logging
import time
import os
import re
from typing import Optional, Tuple, Dict

# Setup detailed logging
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s [%(levelname)s] - %(message)s",
    handlers=[
        logging.FileHandler("m3u8_inspector.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger()

# Constants
M3U8_URL = "https://rr.buytommy.top/s/xyeaS1OrfUf7SRzWKQte3CQuLIyTRC5VVb0yFwaXP8EiXE__D3MOBaLVMb73Bgjq/9-zhaTgwFpZ8FI_PNx0rVrDHarHEzygPHSaTdnv2BKJB5gDI8HN1zC1m0Rve3LmiIlxP_w9zDgWi1TG-9wYI6g/8XMTfMcuN01N3Ww3rfkwCnJc6vIkCNeTWPEWIz2-I1BNDfNQ9xQzyDaW-xdiB4e8/strm.m3u8?md5=r0dvJCq2sHFZ0M6iyT7y1A&expiry=1747343087"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Mobile Safari/537.36",
    "Referer": "https://embedstreams.top/",
    "Accept": "*/*",
    "Origin": "https://embedstreams.top",
}
OUTPUT_DIR = "m3u8_content"
MAX_PREVIEW_BYTES = 200  # Limit for previewing content in logs

def setup_output_directory():
    """Create output directory if it doesn't exist."""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    logger.info(f"Created output directory: {OUTPUT_DIR}")

def sanitize_filename(url: str) -> str:
    """Extract a short, safe filename from a URL."""
    parsed = urllib.parse.urlparse(url)
    base = os.path.basename(parsed.path)
    if not base:
        base = f"resource_{int(time.time())}.bin"
    base = re.sub(r'[^\w\.-]', '_', base)
    return base[:100]

def save_content(url: str, content: bytes, is_text: bool = False):
    """Save content to a file in the output directory with a safe filename."""
    filename = sanitize_filename(url)
    filepath = os.path.join(OUTPUT_DIR, filename)
    try:
        mode = "w" if is_text else "wb"
        with open(filepath, mode) as f:
            if is_text:
                f.write(content.decode("utf-8", errors="ignore"))
            else:
                f.write(content)
        logger.info(f"Saved content to {filepath} ({len(content)} bytes)")
    except Exception as e:
        logger.error(f"Failed to save {filepath}: {str(e)}")

def fetch_url(url: str, retries: int = 3, timeout: int = 20) -> Optional[Tuple[bytes, str, Dict]]:
    """Fetch a URL with retries and log details."""
    start_time = time.time()
    logger.info(f"Fetching URL: {url}")
    logger.debug(f"Headers: {HEADERS}")
    for attempt in range(1, retries + 1):
        logger.info(f"Attempt {attempt} of {retries}")
        req = urllib.request.Request(url, headers=HEADERS)
        try:
            with urllib.request.urlopen(req, timeout=timeout) as response:
                content = response.read()
                content_type = response.getheader("Content-Type", "application/octet-stream")
                headers = dict(response.getheaders())
                elapsed = time.time() - start_time
                logger.info(f"Success: Status {response.status}, Content-Type: {content_type}, Size: {len(content)} bytes")
                logger.debug(f"Response headers: {headers}")
                preview = content[:MAX_PREVIEW_BYTES].decode("utf-8", errors="ignore")
                logger.debug(f"Content preview: {preview}")
                save_content(url, content, is_text=("text" in content_type or "m3u8" in content_type))
                return content, content_type, headers
        except urllib.error.HTTPError as e:
            logger.error(f"HTTP Error: Status {e.code}, Reason: {e.reason}")
            if attempt == retries:
                break
            time.sleep(1)
        except urllib.error.URLError as e:
            logger.error(f"URL Error: {str(e)}")
            if attempt == retries:
                break
            time.sleep(1)
    logger.error(f"All attempts failed for {url}")
    return None

def parse_m3u8(m3u8_content: str) -> Tuple[list, list]:
    """Parse M3U8 to extract segment and key URLs."""
    logger.info("Parsing M3U8 content...")
    segments = []
    keys = []
    lines = m3u8_content.splitlines()
    for line in lines:
        if line.startswith("#EXT-X-KEY") and "URI=" in line:
            try:
                key_url = line.split('URI="')[1].split('"')[0]
                if not key_url.startswith("http"):
                    key_url = urllib.parse.urljoin(M3U8_URL, key_url)
                keys.append(key_url)
                logger.info(f"Found key: {key_url}")
            except IndexError:
                logger.warning(f"Malformed key URI: {line}")
        elif line.startswith("http"):
            segment_url = line.strip()
            if not segment_url.lower().endswith((".ts", ".js")):
                logger.warning(f"Unexpected segment format: {segment_url} (not .ts or .js)")
            segments.append(segment_url)
            logger.info(f"Found segment: {segment_url}")
    logger.info(f"Found {len(segments)} segments and {len(keys)} keys")
    return segments, keys

def validate_m3u8(m3u8_content: str) -> bool:
    """Validate M3U8 content."""
    logger.info("Validating M3U8 content...")
    if not m3u8_content.strip():
        logger.error("M3U8 content is empty")
        return False
    if "#EXTM3U" not in m3u8_content:
        logger.error("M3U8 is invalid: Missing #EXTM3U header")
        return False
    logger.info("M3U8 appears valid")
    return True

def inspect_m3u8():
    """Fetch and inspect all M3U8 content."""
    setup_output_directory()
    # Fetch M3U8 playlist
    logger.info("Starting M3U8 inspection...")
    result = fetch_url(M3U8_URL)
    if not result:
        logger.error("Failed to fetch M3U8 playlist. Exiting.")
        return
    m3u8_content, content_type, headers = result
    if "m3u8" not in content_type.lower() and "text" not in content_type.lower():
        logger.warning(f"Unexpected Content-Type: {content_type} (expected M3U8 content)")
    # Decode and save M3U8
    try:
        m3u8_text = m3u8_content.decode("utf-8", errors="ignore")
        logger.info("M3U8 full content:")
        logger.info("\n" + m3u8_text)
        save_content(M3U8_URL, m3u8_content, is_text=True)
    except Exception as e:
        logger.error(f"Failed to decode M3U8: {str(e)}")
        return
    # Validate M3U8
    if not validate_m3u8(m3u8_text):
        logger.error("Invalid M3U8 playlist. Proceeding to parse anyway.")
    # Parse M3U8 for segments and keys
    segments, keys = parse_m3u8(m3u8_text)
    # Fetch keys
    logger.info("Fetching encryption keys...")
    for key_url in keys:
        fetch_url(key_url)
    # Fetch segments
    logger.info("Fetching media segments...")
    for segment_url in segments:
        fetch_url(segment_url)
    logger.info("Inspection complete. Check output directory and logs for details.")

if __name__ == "__main__":
    try:
        inspect_m3u8()
    except KeyboardInterrupt:
        logger.info("Inspection interrupted by user.")
    except Exception as e:
        logger.error(f"Error during inspection: {str(e)}")